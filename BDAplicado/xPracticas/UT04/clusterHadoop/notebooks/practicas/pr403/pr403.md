```python
%cd practicas/pr403
```

    /media/notebooks/practicas/pr403


    /usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.
      self.shell.db['dhist'] = compress_dhist(dhist)[-100:]



```python
!hdfs dfs -mkdir /pr403
```

    mkdir: `/pr403': File exists



```python
!hdfs dfs -put ./logs.log /pr403
```

    put: `/pr403/logs.log': File exists


# Ejercicio 1


```python
%%writefile mapper1.py
#!/usr/bin/env python3

import sys

for line in sys.stdin:
    line = line.strip().split()
    print(f"{line[8]}, {1}")

```

    Overwriting mapper1.py



```python
%%writefile reducer1.py
#!/usr/bin/env python3


import sys

dic = {}

for line in sys.stdin:
    line = line.strip().split(", ")
    num = int(line[0])
    count = int(line[1])

    if num in dic:
        dic[num] = dic[num] + count
    else:
        dic[num] = count

for num, count in dic.items():
    print(f"{num}: {count}")

```

    Overwriting reducer1.py



```python
!hdfs dfs -rm -r /pr403/salida1
```

    Deleted /pr403/salida1



```python
!hadoop jar \
/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-file mapper1.py \
-file reducer1.py \
-mapper mapper1.py \
-reducer reducer1.py \
-input /pr403/logs.log \
-output /pr403/salida1
```

    2025-12-03 16:54:58,794 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
    packageJobJar: [mapper1.py, reducer1.py, /tmp/hadoop-unjar4699871641485395965/] [] /tmp/streamjob7467766486674358150.jar tmpDir=null
    2025-12-03 16:54:59,389 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.20.0.4:8032
    2025-12-03 16:54:59,495 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.20.0.4:8032
    2025-12-03 16:54:59,699 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1764780814862_0001
    2025-12-03 16:55:00,837 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-12-03 16:55:00,923 INFO mapreduce.JobSubmitter: number of splits:2
    2025-12-03 16:55:01,041 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1764780814862_0001
    2025-12-03 16:55:01,041 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-12-03 16:55:01,214 INFO conf.Configuration: resource-types.xml not found
    2025-12-03 16:55:01,215 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-12-03 16:55:01,870 INFO impl.YarnClientImpl: Submitted application application_1764780814862_0001
    2025-12-03 16:55:01,977 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1764780814862_0001/
    2025-12-03 16:55:01,980 INFO mapreduce.Job: Running job: job_1764780814862_0001
    2025-12-03 16:55:09,627 INFO mapreduce.Job: Job job_1764780814862_0001 running in uber mode : false
    2025-12-03 16:55:09,628 INFO mapreduce.Job:  map 0% reduce 0%
    2025-12-03 16:55:15,731 INFO mapreduce.Job:  map 100% reduce 0%
    2025-12-03 16:55:21,761 INFO mapreduce.Job:  map 100% reduce 100%
    2025-12-03 16:55:21,767 INFO mapreduce.Job: Job job_1764780814862_0001 completed successfully
    2025-12-03 16:55:21,822 INFO mapreduce.Job: Counters: 54
    	File System Counters
    		FILE: Number of bytes read=1006
    		FILE: Number of bytes written=944419
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=28591
    		HDFS: Number of bytes written=62
    		HDFS: Number of read operations=11
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=2
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Launched reduce tasks=1
    		Data-local map tasks=2
    		Total time spent by all maps in occupied slots (ms)=8178
    		Total time spent by all reduces in occupied slots (ms)=2802
    		Total time spent by all map tasks (ms)=8178
    		Total time spent by all reduce tasks (ms)=2802
    		Total vcore-milliseconds taken by all map tasks=8178
    		Total vcore-milliseconds taken by all reduce tasks=2802
    		Total megabyte-milliseconds taken by all map tasks=8374272
    		Total megabyte-milliseconds taken by all reduce tasks=2869248
    	Map-Reduce Framework
    		Map input records=100
    		Map output records=100
    		Map output bytes=800
    		Map output materialized bytes=1012
    		Input split bytes=174
    		Combine input records=0
    		Combine output records=0
    		Reduce input groups=7
    		Reduce shuffle bytes=1012
    		Reduce input records=100
    		Reduce output records=7
    		Spilled Records=200
    		Shuffled Maps =2
    		Failed Shuffles=0
    		Merged Map outputs=2
    		GC time elapsed (ms)=144
    		CPU time spent (ms)=2210
    		Physical memory (bytes) snapshot=930402304
    		Virtual memory (bytes) snapshot=7809896448
    		Total committed heap usage (bytes)=710410240
    		Peak Map Physical memory (bytes)=343158784
    		Peak Map Virtual memory (bytes)=2602037248
    		Peak Reduce Physical memory (bytes)=244289536
    		Peak Reduce Virtual memory (bytes)=2606391296
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters 
    		Bytes Read=28417
    	File Output Format Counters 
    		Bytes Written=62
    2025-12-03 16:55:21,822 INFO streaming.StreamJob: Output directory: /pr403/salida1



```python
!hdfs dfs -cat /pr403/salida1/part-00000
```

    200: 15	
    303: 15	
    304: 17	
    403: 8	
    404: 12	
    500: 15	
    502: 18	



```python
!cat logs.log | python3 mapper1.py | sort | python3 reducer1.py 
```

    200: 15
    303: 15
    304: 17
    403: 8
    404: 12
    500: 15
    502: 18


# Tráfico Total por IP


```python
%%writefile mapper2.py
#!/usr/bin/env python3

import sys

for line in sys.stdin:
    line = line.strip().split()
    ip = line[0]
    if line[9] == "-":
         bytes = 0
    else:
        bytes = int(line[9])

print(f"{ip}, {bytes}")
```

    Overwriting mapper2.py



```python
%%writefile reducer2.py
#!/usr/bin/env python3

import sys

dic = {}

for line in sys.stdin:
    line = line.strip().split(",")
    ip = line[0]
    bytes = int(line[1])

    if ip in dic:
        dic[ip] = dic[ip] + bytes
    else:
        dic[ip] = bytes

for ip, bytes in dic.items(): 
    print(f"{ip}: {bytes} bytes")
```

    Overwriting reducer2.py



```python
!hdfs dfs -rm -r /pr403/salida2
```

    Deleted /pr403/salida2



```python
!hadoop jar \
/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-file mapper2.py \
-file reducer2.py \
-mapper mapper2.py \
-reducer reducer2.py \
-input /pr403/logs.log \
-output /pr403/salida2
```

    2025-12-03 17:10:45,963 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
    packageJobJar: [mapper2.py, reducer2.py, /tmp/hadoop-unjar8038086215335020674/] [] /tmp/streamjob3828672126128387049.jar tmpDir=null
    2025-12-03 17:10:46,625 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.20.0.4:8032
    2025-12-03 17:10:46,746 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.20.0.4:8032
    2025-12-03 17:10:46,916 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1764780814862_0006
    2025-12-03 17:10:47,180 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-12-03 17:10:47,235 INFO mapreduce.JobSubmitter: number of splits:2
    2025-12-03 17:10:47,314 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1764780814862_0006
    2025-12-03 17:10:47,314 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-12-03 17:10:47,437 INFO conf.Configuration: resource-types.xml not found
    2025-12-03 17:10:47,437 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-12-03 17:10:47,489 INFO impl.YarnClientImpl: Submitted application application_1764780814862_0006
    2025-12-03 17:10:47,520 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1764780814862_0006/
    2025-12-03 17:10:47,521 INFO mapreduce.Job: Running job: job_1764780814862_0006
    2025-12-03 17:10:51,816 INFO mapreduce.Job: Job job_1764780814862_0006 running in uber mode : false
    2025-12-03 17:10:51,818 INFO mapreduce.Job:  map 0% reduce 0%
    2025-12-03 17:10:55,889 INFO mapreduce.Job:  map 100% reduce 0%
    2025-12-03 17:11:00,913 INFO mapreduce.Job:  map 100% reduce 100%
    2025-12-03 17:11:00,921 INFO mapreduce.Job: Job job_1764780814862_0006 completed successfully
    2025-12-03 17:11:00,984 INFO mapreduce.Job: Counters: 54
    	File System Counters
    		FILE: Number of bytes read=51
    		FILE: Number of bytes written=942509
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=28591
    		HDFS: Number of bytes written=53
    		HDFS: Number of read operations=11
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=2
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Launched reduce tasks=1
    		Data-local map tasks=2
    		Total time spent by all maps in occupied slots (ms)=3562
    		Total time spent by all reduces in occupied slots (ms)=2315
    		Total time spent by all map tasks (ms)=3562
    		Total time spent by all reduce tasks (ms)=2315
    		Total vcore-milliseconds taken by all map tasks=3562
    		Total vcore-milliseconds taken by all reduce tasks=2315
    		Total megabyte-milliseconds taken by all map tasks=3647488
    		Total megabyte-milliseconds taken by all reduce tasks=2370560
    	Map-Reduce Framework
    		Map input records=100
    		Map output records=2
    		Map output bytes=41
    		Map output materialized bytes=57
    		Input split bytes=174
    		Combine input records=0
    		Combine output records=0
    		Reduce input groups=2
    		Reduce shuffle bytes=57
    		Reduce input records=2
    		Reduce output records=2
    		Spilled Records=4
    		Shuffled Maps =2
    		Failed Shuffles=0
    		Merged Map outputs=2
    		GC time elapsed (ms)=120
    		CPU time spent (ms)=1620
    		Physical memory (bytes) snapshot=929218560
    		Virtual memory (bytes) snapshot=7803904000
    		Total committed heap usage (bytes)=717750272
    		Peak Map Physical memory (bytes)=347271168
    		Peak Map Virtual memory (bytes)=2601316352
    		Peak Reduce Physical memory (bytes)=238395392
    		Peak Reduce Virtual memory (bytes)=2604576768
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters 
    		Bytes Read=28417
    	File Output Format Counters 
    		Bytes Written=53
    2025-12-03 17:11:00,984 INFO streaming.StreamJob: Output directory: /pr403/salida2



```python
!hdfs dfs -cat /pr403/salida2/part-00000
```

    250.68.88.150: 4972 bytes	
    46.141.41.90: 4981 bytes	


# 2. Análisis de comportamiento
## URLS más pupulares


```python
%%writefile mapper3.py
#!/usr/bin/env python3

import sys

for line in sys.stdin:
    line = line.strip().split()
    url = line[6]

    print(f"{url}, {1}")
```

    Overwriting mapper3.py



```python
%%writefile reducer3.py
#!/usr/bin/env python3

import sys

dic = {}

for line in sys.stdin:
    line = line.strip().split()
    url = line[0]
    count = int(line[1])

    if url in dic:
        dic[url] = dic[url] + count
    else:
        dic[url] = count

for url, count in dic.items():
    print(f"{url}, {count}")
```

    Overwriting reducer3.py



```python
!hdfs dfs -rm -r /pr403/salida3
```

    Deleted /pr403/salida3



```python
!hadoop jar \
/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-file mapper3.py \
-file reducer3.py \
-mapper mapper3.py \
-reducer reducer3.py \
-input /pr403/logs.log \
-output /pr403/salida3
```

    2025-12-03 17:27:08,021 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
    packageJobJar: [mapper3.py, reducer3.py, /tmp/hadoop-unjar4582899542856014381/] [] /tmp/streamjob9214678586365403708.jar tmpDir=null
    2025-12-03 17:27:08,591 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.20.0.4:8032
    2025-12-03 17:27:08,707 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.20.0.4:8032
    2025-12-03 17:27:08,849 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1764780814862_0011
    2025-12-03 17:27:09,167 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-12-03 17:27:09,258 INFO mapreduce.JobSubmitter: number of splits:2
    2025-12-03 17:27:09,350 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1764780814862_0011
    2025-12-03 17:27:09,350 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-12-03 17:27:09,493 INFO conf.Configuration: resource-types.xml not found
    2025-12-03 17:27:09,493 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-12-03 17:27:09,558 INFO impl.YarnClientImpl: Submitted application application_1764780814862_0011
    2025-12-03 17:27:09,592 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1764780814862_0011/
    2025-12-03 17:27:09,593 INFO mapreduce.Job: Running job: job_1764780814862_0011
    2025-12-03 17:27:13,664 INFO mapreduce.Job: Job job_1764780814862_0011 running in uber mode : false
    2025-12-03 17:27:13,666 INFO mapreduce.Job:  map 0% reduce 0%
    2025-12-03 17:27:17,732 INFO mapreduce.Job:  map 100% reduce 0%
    2025-12-03 17:27:21,757 INFO mapreduce.Job:  map 100% reduce 100%
    2025-12-03 17:27:21,764 INFO mapreduce.Job: Job job_1764780814862_0011 completed successfully
    2025-12-03 17:27:21,822 INFO mapreduce.Job: Counters: 54
    	File System Counters
    		FILE: Number of bytes read=1811
    		FILE: Number of bytes written=946029
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=28591
    		HDFS: Number of bytes written=92
    		HDFS: Number of read operations=11
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=2
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Launched reduce tasks=1
    		Data-local map tasks=2
    		Total time spent by all maps in occupied slots (ms)=3574
    		Total time spent by all reduces in occupied slots (ms)=1596
    		Total time spent by all map tasks (ms)=3574
    		Total time spent by all reduce tasks (ms)=1596
    		Total vcore-milliseconds taken by all map tasks=3574
    		Total vcore-milliseconds taken by all reduce tasks=1596
    		Total megabyte-milliseconds taken by all map tasks=3659776
    		Total megabyte-milliseconds taken by all reduce tasks=1634304
    	Map-Reduce Framework
    		Map input records=100
    		Map output records=100
    		Map output bytes=1605
    		Map output materialized bytes=1817
    		Input split bytes=174
    		Combine input records=0
    		Combine output records=0
    		Reduce input groups=5
    		Reduce shuffle bytes=1817
    		Reduce input records=100
    		Reduce output records=5
    		Spilled Records=200
    		Shuffled Maps =2
    		Failed Shuffles=0
    		Merged Map outputs=2
    		GC time elapsed (ms)=115
    		CPU time spent (ms)=1620
    		Physical memory (bytes) snapshot=934154240
    		Virtual memory (bytes) snapshot=7807586304
    		Total committed heap usage (bytes)=723517440
    		Peak Map Physical memory (bytes)=346570752
    		Peak Map Virtual memory (bytes)=2600878080
    		Peak Reduce Physical memory (bytes)=243449856
    		Peak Reduce Virtual memory (bytes)=2606280704
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters 
    		Bytes Read=28417
    	File Output Format Counters 
    		Bytes Written=92
    2025-12-03 17:27:21,822 INFO streaming.StreamJob: Output directory: /pr403/salida3



```python
!hdfs dfs -cat /pr403/salida3/part-00000
```

    /usr,, 23	
    /usr/admin,, 17	
    /usr/admin/developer,, 18	
    /usr/login,, 21	
    /usr/register,, 21	


## Distribución por método HTTP


```python
%%writefile mapper4.py
#!/usr/bin/env python3

import sys

for line in sys.stdin:
    line = line.strip().split()
    http = line[5]
    print(f"{http}, {1}")
```

    Overwriting mapper4.py



```python
%%writefile reducer4.py
#!/usr/bin/env python3

import sys

dic = {}

for line in sys.stdin:
    line = line.strip().split(",")
    http = line[0]
    count = int(line[1])

    if http in dic:
        dic[http] = dic[http] + count
    else:
        dic[http] = count

for http, count in dic.items():
    print(f"{http}, {count}")
```

    Overwriting reducer4.py



```python
!hdfs dfs -rm -r /pr403/salida4
```

    Deleted /pr403/salida4



```python
!hadoop jar \
/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-file mapper4.py \
-file reducer4.py \
-mapper mapper4.py \
-reducer reducer4.py \
-input /pr403/logs.log \
-output /pr403/salida4
```

    2025-12-06 17:55:37,996 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
    packageJobJar: [mapper4.py, reducer4.py, /tmp/hadoop-unjar5139796246872456713/] [] /tmp/streamjob5726218660135801296.jar tmpDir=null
    2025-12-06 17:55:38,654 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.20.0.3:8032
    2025-12-06 17:55:38,790 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.20.0.3:8032
    2025-12-06 17:55:38,969 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1765043067955_0002
    2025-12-06 17:55:39,289 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-12-06 17:55:39,355 INFO mapreduce.JobSubmitter: number of splits:2
    2025-12-06 17:55:39,442 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1765043067955_0002
    2025-12-06 17:55:39,442 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-12-06 17:55:39,568 INFO conf.Configuration: resource-types.xml not found
    2025-12-06 17:55:39,568 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-12-06 17:55:39,627 INFO impl.YarnClientImpl: Submitted application application_1765043067955_0002
    2025-12-06 17:55:39,657 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1765043067955_0002/
    2025-12-06 17:55:39,658 INFO mapreduce.Job: Running job: job_1765043067955_0002
    2025-12-06 17:55:44,731 INFO mapreduce.Job: Job job_1765043067955_0002 running in uber mode : false
    2025-12-06 17:55:44,731 INFO mapreduce.Job:  map 0% reduce 0%
    2025-12-06 17:55:54,287 INFO mapreduce.Job:  map 100% reduce 0%
    2025-12-06 17:55:58,315 INFO mapreduce.Job:  map 100% reduce 100%
    2025-12-06 17:55:58,323 INFO mapreduce.Job: Job job_1765043067955_0002 completed successfully
    2025-12-06 17:55:58,393 INFO mapreduce.Job: Counters: 54
    	File System Counters
    		FILE: Number of bytes read=1199
    		FILE: Number of bytes written=944805
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=28591
    		HDFS: Number of bytes written=44
    		HDFS: Number of read operations=11
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=2
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Launched reduce tasks=1
    		Data-local map tasks=2
    		Total time spent by all maps in occupied slots (ms)=12111
    		Total time spent by all reduces in occupied slots (ms)=1702
    		Total time spent by all map tasks (ms)=12111
    		Total time spent by all reduce tasks (ms)=1702
    		Total vcore-milliseconds taken by all map tasks=12111
    		Total vcore-milliseconds taken by all reduce tasks=1702
    		Total megabyte-milliseconds taken by all map tasks=12401664
    		Total megabyte-milliseconds taken by all reduce tasks=1742848
    	Map-Reduce Framework
    		Map input records=100
    		Map output records=100
    		Map output bytes=993
    		Map output materialized bytes=1205
    		Input split bytes=174
    		Combine input records=0
    		Combine output records=0
    		Reduce input groups=4
    		Reduce shuffle bytes=1205
    		Reduce input records=100
    		Reduce output records=4
    		Spilled Records=200
    		Shuffled Maps =2
    		Failed Shuffles=0
    		Merged Map outputs=2
    		GC time elapsed (ms)=162
    		CPU time spent (ms)=3000
    		Physical memory (bytes) snapshot=913100800
    		Virtual memory (bytes) snapshot=7807094784
    		Total committed heap usage (bytes)=717225984
    		Peak Map Physical memory (bytes)=345694208
    		Peak Map Virtual memory (bytes)=2600259584
    		Peak Reduce Physical memory (bytes)=242614272
    		Peak Reduce Virtual memory (bytes)=2608689152
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters 
    		Bytes Read=28417
    	File Output Format Counters 
    		Bytes Written=44
    2025-12-06 17:55:58,393 INFO streaming.StreamJob: Output directory: /pr403/salida4



```python
!hdfs dfs -cat /pr403/salida4/part-00000
```

    "DELETE, 23	
    "GET, 25	
    "POST, 24	
    "PUT, 28	


## Analisis de navegadores


```python
%%writefile mapper5.py
#!/usr/bin/env python3

import sys

for line in sys.stdin:
    line = line.strip().split()
    navegador = line[11]
    print(f"{navegador}, {1}")
```

    Overwriting mapper5.py



```python
%%writefile reducer5.py
#!/usr/bin/env python3

import sys

dic = {}

for line in sys.stdin:
    line = line.strip().split(",")
    line = line[0]
    if line in dic:
        dic[line] = dic[line] + 1
    else:
        dic[line] = 1

for line, count in dic.items():
    print(f"{line}, {count}")
```

    Overwriting reducer5.py



```python
!hdfs dfs -rm -r /pr403/salida5
```

    Deleted /pr403/salida5



```python
!hadoop jar \
/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-file mapper5.py \
-file reducer5.py \
-mapper mapper5.py \
-reducer reducer5.py \
-input /pr403/logs.log \
-output /pr403/salida5
```

    2025-12-06 18:08:21,357 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
    packageJobJar: [mapper5.py, reducer5.py, /tmp/hadoop-unjar6973581599727951154/] [] /tmp/streamjob2358296235929841562.jar tmpDir=null
    2025-12-06 18:08:21,876 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.20.0.3:8032
    2025-12-06 18:08:21,979 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.20.0.3:8032
    2025-12-06 18:08:22,129 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1765043067955_0006
    2025-12-06 18:08:22,449 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-12-06 18:08:22,535 INFO mapreduce.JobSubmitter: number of splits:2
    2025-12-06 18:08:22,635 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1765043067955_0006
    2025-12-06 18:08:22,635 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-12-06 18:08:22,797 INFO conf.Configuration: resource-types.xml not found
    2025-12-06 18:08:22,797 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-12-06 18:08:22,865 INFO impl.YarnClientImpl: Submitted application application_1765043067955_0006
    2025-12-06 18:08:22,906 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1765043067955_0006/
    2025-12-06 18:08:22,907 INFO mapreduce.Job: Running job: job_1765043067955_0006
    2025-12-06 18:08:27,965 INFO mapreduce.Job: Job job_1765043067955_0006 running in uber mode : false
    2025-12-06 18:08:27,966 INFO mapreduce.Job:  map 0% reduce 0%
    2025-12-06 18:08:32,028 INFO mapreduce.Job:  map 100% reduce 0%
    2025-12-06 18:08:36,048 INFO mapreduce.Job:  map 100% reduce 100%
    2025-12-06 18:08:36,054 INFO mapreduce.Job: Job job_1765043067955_0006 completed successfully
    2025-12-06 18:08:36,104 INFO mapreduce.Job: Counters: 54
    	File System Counters
    		FILE: Number of bytes read=1906
    		FILE: Number of bytes written=946219
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=28591
    		HDFS: Number of bytes written=19
    		HDFS: Number of read operations=11
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=2
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Launched reduce tasks=1
    		Data-local map tasks=2
    		Total time spent by all maps in occupied slots (ms)=3799
    		Total time spent by all reduces in occupied slots (ms)=1639
    		Total time spent by all map tasks (ms)=3799
    		Total time spent by all reduce tasks (ms)=1639
    		Total vcore-milliseconds taken by all map tasks=3799
    		Total vcore-milliseconds taken by all reduce tasks=1639
    		Total megabyte-milliseconds taken by all map tasks=3890176
    		Total megabyte-milliseconds taken by all reduce tasks=1678336
    	Map-Reduce Framework
    		Map input records=100
    		Map output records=100
    		Map output bytes=1700
    		Map output materialized bytes=1912
    		Input split bytes=174
    		Combine input records=0
    		Combine output records=0
    		Reduce input groups=1
    		Reduce shuffle bytes=1912
    		Reduce input records=100
    		Reduce output records=1
    		Spilled Records=200
    		Shuffled Maps =2
    		Failed Shuffles=0
    		Merged Map outputs=2
    		GC time elapsed (ms)=127
    		CPU time spent (ms)=1460
    		Physical memory (bytes) snapshot=934010880
    		Virtual memory (bytes) snapshot=7805988864
    		Total committed heap usage (bytes)=719847424
    		Peak Map Physical memory (bytes)=348753920
    		Peak Map Virtual memory (bytes)=2600890368
    		Peak Reduce Physical memory (bytes)=240488448
    		Peak Reduce Virtual memory (bytes)=2605465600
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters 
    		Bytes Read=28417
    	File Output Format Counters 
    		Bytes Written=19
    2025-12-06 18:08:36,105 INFO streaming.StreamJob: Output directory: /pr403/salida5



```python
!hdfs dfs -cat /pr403/salida5/part-00000
```

    "Mozilla/5.0, 100	


# 3. Análisis temporal de sesión
## Picos de tráfico por horas


```python
%%writefile mapper6.py
#!/usr/bin/env python3

import sys

for line in sys.stdin:
    line = line.strip().split()
    
    fecha = line[3]
    fecha = fecha.strip().split(":")
    hora = fecha[1]
    print(f"{hora}, {1}")
```

    Writing mapper6.py



```python
%%writefile reducer6.py
#!/usr/bin/env python3

import sys

dic = {}

for line in sys.stdin:
    line = line.strip().split(",")
    hora = line[0]
    count = int(line[1])
    if hora in dic:
        dic[hora] = dic[hora] + count
    else:
        dic[hora] = count

for hora, count in dic.items():
    print(f"{hora}, {count}")
```

    Overwriting reducer6.py



```python
!hdfs dfs -rm -r /pr403/salida6
```

    Deleted /pr403/salida6



```python
!hadoop jar \
/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-file mapper6.py \
-file reducer6.py \
-mapper mapper6.py \
-reducer reducer6.py \
-input /pr403/logs.log \
-output /pr403/salida6
```

    2025-12-06 18:15:37,885 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
    packageJobJar: [mapper6.py, reducer6.py, /tmp/hadoop-unjar2129959955085644586/] [] /tmp/streamjob1954031514229764434.jar tmpDir=null
    2025-12-06 18:15:38,424 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.20.0.3:8032
    2025-12-06 18:15:38,537 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.20.0.3:8032
    2025-12-06 18:15:38,684 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1765043067955_0009
    2025-12-06 18:15:39,034 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-12-06 18:15:39,136 INFO mapreduce.JobSubmitter: number of splits:2
    2025-12-06 18:15:39,289 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1765043067955_0009
    2025-12-06 18:15:39,290 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-12-06 18:15:39,476 INFO conf.Configuration: resource-types.xml not found
    2025-12-06 18:15:39,477 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-12-06 18:15:39,549 INFO impl.YarnClientImpl: Submitted application application_1765043067955_0009
    2025-12-06 18:15:39,594 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1765043067955_0009/
    2025-12-06 18:15:39,595 INFO mapreduce.Job: Running job: job_1765043067955_0009
    2025-12-06 18:15:43,678 INFO mapreduce.Job: Job job_1765043067955_0009 running in uber mode : false
    2025-12-06 18:15:43,679 INFO mapreduce.Job:  map 0% reduce 0%
    2025-12-06 18:15:47,757 INFO mapreduce.Job:  map 100% reduce 0%
    2025-12-06 18:15:52,792 INFO mapreduce.Job:  map 100% reduce 100%
    2025-12-06 18:15:52,801 INFO mapreduce.Job: Job job_1765043067955_0009 completed successfully
    2025-12-06 18:15:52,855 INFO mapreduce.Job: Counters: 54
    	File System Counters
    		FILE: Number of bytes read=906
    		FILE: Number of bytes written=944219
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=28591
    		HDFS: Number of bytes written=9
    		HDFS: Number of read operations=11
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=2
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Launched reduce tasks=1
    		Data-local map tasks=2
    		Total time spent by all maps in occupied slots (ms)=3843
    		Total time spent by all reduces in occupied slots (ms)=1577
    		Total time spent by all map tasks (ms)=3843
    		Total time spent by all reduce tasks (ms)=1577
    		Total vcore-milliseconds taken by all map tasks=3843
    		Total vcore-milliseconds taken by all reduce tasks=1577
    		Total megabyte-milliseconds taken by all map tasks=3935232
    		Total megabyte-milliseconds taken by all reduce tasks=1614848
    	Map-Reduce Framework
    		Map input records=100
    		Map output records=100
    		Map output bytes=700
    		Map output materialized bytes=912
    		Input split bytes=174
    		Combine input records=0
    		Combine output records=0
    		Reduce input groups=1
    		Reduce shuffle bytes=912
    		Reduce input records=100
    		Reduce output records=1
    		Spilled Records=200
    		Shuffled Maps =2
    		Failed Shuffles=0
    		Merged Map outputs=2
    		GC time elapsed (ms)=118
    		CPU time spent (ms)=1500
    		Physical memory (bytes) snapshot=914976768
    		Virtual memory (bytes) snapshot=7803203584
    		Total committed heap usage (bytes)=714080256
    		Peak Map Physical memory (bytes)=344784896
    		Peak Map Virtual memory (bytes)=2599632896
    		Peak Reduce Physical memory (bytes)=246267904
    		Peak Reduce Virtual memory (bytes)=2604134400
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters 
    		Bytes Read=28417
    	File Output Format Counters 
    		Bytes Written=9
    2025-12-06 18:15:52,856 INFO streaming.StreamJob: Output directory: /pr403/salida6



```python
!hdfs dfs -cat /pr403/salida6/part-00000
```

    12, 100	


## Tasa de error por endPoint


```python
%%writefile mapper7.py
#!/usr/bin/env python3

import sys

codigo = None

for line in sys.stdin:
    line = line.strip().split()
    url = line[6]
    cod = int(line[8])

    if cod >= 400:
        codigo = "error"
    else:
        codigo = "ok"

    print(f"{url}, {codigo}")
```

    Overwriting mapper7.py



```python
%%writefile reducer7.py
#!/usr/bin/env python3

import sys

total = 0
errores = 0

for line in sys.stdin:
    total = total + 1

    line = line.strip().split(",")
    url = line[0]
    codigo = str(line[1])

    if "error" in codigo:
        errores = errores + 1

print(f"ERRORES TOTALES: {(errores / total) * 100}%")
```

    Overwriting reducer7.py



```python
!hdfs dfs -rm -r /pr403/salida7
```

    Deleted /pr403/salida7



```python
!hadoop jar \
/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-file mapper7.py \
-file reducer7.py \
-mapper mapper7.py \
-reducer reducer7.py \
-input /pr403/logs.log \
-output /pr403/salida7
```

    2025-12-06 18:30:19,511 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
    packageJobJar: [mapper7.py, reducer7.py, /tmp/hadoop-unjar255563278939809025/] [] /tmp/streamjob5016497248822100873.jar tmpDir=null
    2025-12-06 18:30:20,133 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.20.0.3:8032
    2025-12-06 18:30:20,240 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.20.0.3:8032
    2025-12-06 18:30:20,419 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1765043067955_0017
    2025-12-06 18:30:20,798 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-12-06 18:30:20,889 INFO mapreduce.JobSubmitter: number of splits:2
    2025-12-06 18:30:20,990 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1765043067955_0017
    2025-12-06 18:30:20,990 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-12-06 18:30:21,130 INFO conf.Configuration: resource-types.xml not found
    2025-12-06 18:30:21,130 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-12-06 18:30:21,185 INFO impl.YarnClientImpl: Submitted application application_1765043067955_0017
    2025-12-06 18:30:21,214 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1765043067955_0017/
    2025-12-06 18:30:21,215 INFO mapreduce.Job: Running job: job_1765043067955_0017
    2025-12-06 18:30:25,279 INFO mapreduce.Job: Job job_1765043067955_0017 running in uber mode : false
    2025-12-06 18:30:25,280 INFO mapreduce.Job:  map 0% reduce 0%
    2025-12-06 18:30:29,323 INFO mapreduce.Job:  map 100% reduce 0%
    2025-12-06 18:30:34,353 INFO mapreduce.Job:  map 100% reduce 100%
    2025-12-06 18:30:34,360 INFO mapreduce.Job: Job job_1765043067955_0017 completed successfully
    2025-12-06 18:30:34,439 INFO mapreduce.Job: Counters: 54
    	File System Counters
    		FILE: Number of bytes read=2070
    		FILE: Number of bytes written=946547
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=28591
    		HDFS: Number of bytes written=24
    		HDFS: Number of read operations=11
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=2
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Launched reduce tasks=1
    		Data-local map tasks=2
    		Total time spent by all maps in occupied slots (ms)=3990
    		Total time spent by all reduces in occupied slots (ms)=1541
    		Total time spent by all map tasks (ms)=3990
    		Total time spent by all reduce tasks (ms)=1541
    		Total vcore-milliseconds taken by all map tasks=3990
    		Total vcore-milliseconds taken by all reduce tasks=1541
    		Total megabyte-milliseconds taken by all map tasks=4085760
    		Total megabyte-milliseconds taken by all reduce tasks=1577984
    	Map-Reduce Framework
    		Map input records=100
    		Map output records=100
    		Map output bytes=1864
    		Map output materialized bytes=2076
    		Input split bytes=174
    		Combine input records=0
    		Combine output records=0
    		Reduce input groups=10
    		Reduce shuffle bytes=2076
    		Reduce input records=100
    		Reduce output records=1
    		Spilled Records=200
    		Shuffled Maps =2
    		Failed Shuffles=0
    		Merged Map outputs=2
    		GC time elapsed (ms)=145
    		CPU time spent (ms)=1670
    		Physical memory (bytes) snapshot=910970880
    		Virtual memory (bytes) snapshot=7808045056
    		Total committed heap usage (bytes)=713555968
    		Peak Map Physical memory (bytes)=347021312
    		Peak Map Virtual memory (bytes)=2600710144
    		Peak Reduce Physical memory (bytes)=240898048
    		Peak Reduce Virtual memory (bytes)=2607497216
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters 
    		Bytes Read=28417
    	File Output Format Counters 
    		Bytes Written=24
    2025-12-06 18:30:34,439 INFO streaming.StreamJob: Output directory: /pr403/salida7



```python
!hdfs dfs -cat /pr403/salida7/part-00000
```

    ERRORES TOTALES: 53.0%	

